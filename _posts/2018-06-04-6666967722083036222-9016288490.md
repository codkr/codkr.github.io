---                
layout: post       
title: 基于SPARK，数据清洗           
description: '<div class="content"></br><p class="">一、需求描述：</p></br><p class="">第一步：ftp程序从日志服务器上下载日志（包含上线和下线日志）保存到分布式文件系统（hadoop）中(此步骤已完成 )</br><br/>第二步：spark分析程序按照业务规则将  保存在hadoop中的日志文件 清洗和筛选后，存放到mysql数据库中  （此步骤不能正常进行）</p></br><p class="">二、人才需求：</p></br><p class="">精通scala语言， 精通 hadoop 和 spark 集群环境的搭建和spark分析程序的编写，熟悉mysql。</p></br></div>'     
contenturl: https://shixian.com/jobs/9016288490      
tags: [数据挖掘/爬虫,远程]            
salary: 预估5000元          
publish_time: '已发布 17 小时'         
start_time: '2018-06-04 17:15:02'           
apply: 1                   
time_range: 5天              
status: 招募中                  
---                 
